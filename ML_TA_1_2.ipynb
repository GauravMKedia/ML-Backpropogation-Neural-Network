{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4781b224",
      "metadata": {
        "id": "4781b224"
      },
      "source": [
        "# <center>Shri Ramdeobaba College of Engineering and Management , Nagpur</center>\n",
        "### <center>Subject Name : Machine Learning</center>\n",
        "### <center>Assignment : TA-1</center>\n",
        "### Student Name\n",
        "#### 1.) Jiya Rathi , E-13\n",
        "#### 2.) Vinayak Soni , E-67\n",
        "#### 3.) Gaurav Kedia , E-39\n",
        "#### 4.) Ankan Deb, E-30"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6c28581",
      "metadata": {
        "id": "b6c28581"
      },
      "source": [
        "## Problem Statement\n",
        "This definition include: gather some .mp3 and .mp4 files around 1000.\n",
        "Consider 90% of data as a training data and 10% of data as a test data.\n",
        "Convert those files into features matrix. Apply backpropagation neural\n",
        "network to learn whether these are .mp3 or .mp4 files. Plot training and\n",
        "testing accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aff259c",
      "metadata": {
        "id": "7aff259c"
      },
      "source": [
        "## Assignment Phases\n",
        "### 1. Data Preprocessing\n",
        "### 2. Defining our model and training\n",
        "### 3. Testing our model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c65bad9",
      "metadata": {
        "id": "7c65bad9"
      },
      "source": [
        "## Step 1.) Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5c5d5f",
      "metadata": {
        "id": "0f5c5d5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tinytag import TinyTag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd0f57a2",
      "metadata": {
        "id": "dd0f57a2",
        "outputId": "80d3fe66-a46e-4454-e5e1-3ae0d8d4c614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 5.090666666666667, \"extra\": {}, \"filesize\": 30717, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 5.666666666666667, \"extra\": {}, \"filesize\": 34173, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 3.7586666666666666, \"extra\": {}, \"filesize\": 22725, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}, {\"album\": null, \"albumartist\": null, \"artist\": null, \"audio_offset\": 45, \"bitrate\": 48.0, \"channels\": 1, \"comment\": null, \"composer\": null, \"disc\": null, \"disc_total\": null, \"duration\": 7.286666666666667, \"extra\": {}, \"filesize\": 43893, \"genre\": null, \"samplerate\": 32000, \"title\": null, \"track\": null, \"track_total\": null, \"year\": null}]\n"
          ]
        }
      ],
      "source": [
        "file = [None]*1000\n",
        "for i in range(500):\n",
        "    file[i] = TinyTag.get(r'dhwani'+str(i)+'.mp3')\n",
        "for i in range(500,808):\n",
        "    file[i] = TinyTag.get(r'dhwani'+str(i)+'.mp3')\n",
        "for i in range(808, 1000):\n",
        "    j = i - 808\n",
        "    file[i] = TinyTag.get(r'video' + str(j)+'.mp4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b680a6b",
      "metadata": {
        "id": "7b680a6b",
        "outputId": "e53333de-5cec-420c-e906-6b3f2b18d0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X : <class 'numpy.ndarray'>\n",
            "y : <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "feature = [None]*1000\n",
        "for i in range(1000):\n",
        "    data1 = (file[i].filesize/file[i].duration)\n",
        "    data2 = file[i].samplerate\n",
        "    if file[i].audio_offset == None:\n",
        "        data3 = 0\n",
        "    else:\n",
        "        data3 = file[i].audio_offset\n",
        "    if file[i].bitrate == 'None':\n",
        "        data4 = 0\n",
        "    else:\n",
        "        data4 = file[i].bitrate\n",
        "    feature[i] = [data1, data2, data3, data4]\n",
        "# Data1 = filesize vs time\n",
        "# Data2 = Samplerate\n",
        "# Data3 = audio_offset\n",
        "# Data4 = bitrate\n",
        "X = np.array(feature)\n",
        "print(\"Feature of x:\",feature)\n",
        "output = [None]*1000\n",
        "for i in range(808):\n",
        "    output[i] = [1]\n",
        "for i in range (808, 1000):\n",
        "    output[i] = [0]\n",
        "y = np.array(output)\n",
        "print(\"y\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec36447",
      "metadata": {
        "id": "1ec36447"
      },
      "outputs": [],
      "source": [
        "X  = X / np.amax(X,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6deac8d",
      "metadata": {
        "id": "d6deac8d"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "240a66df",
      "metadata": {
        "id": "240a66df"
      },
      "source": [
        "## Step 2.) Defining our Back-Propagation model and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f7c596",
      "metadata": {
        "id": "08f7c596"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "iterations = 3000\n",
        "N = y_train.size\n",
        "input_size = 4\n",
        "hidden_size = 4 \n",
        "output_size = 1  \n",
        "results = pd.DataFrame(columns=[\"mse\", \"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab859c1",
      "metadata": {
        "id": "bab859c1"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "W1 = np.random.normal(scale=0.5, size=(input_size, hidden_size))   \n",
        "W2 = np.random.normal(scale=0.5, size=(hidden_size , output_size)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323248b2",
      "metadata": {
        "id": "323248b2"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(y_pred, y_true):\n",
        "    return ((y_pred - y_true)**2).sum() / (2*y_pred.size)\n",
        "    \n",
        "def accuracy(y_pred, y_true):\n",
        "    acc = y_pred.argmax(axis=1) == y_true.argmax(axis=1)\n",
        "    return acc.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721fcd38",
      "metadata": {
        "id": "721fcd38"
      },
      "outputs": [],
      "source": [
        "\n",
        "for itr in range(iterations):    \n",
        "    \n",
        "    # feedforward propagation\n",
        "    # on hidden layer\n",
        "    Z1 = np.dot(X_train, W1)\n",
        "    A1 = sigmoid(Z1)\n",
        "\n",
        "    # on output layer\n",
        "    Z2 = np.dot(A1, W2)\n",
        "    A2 = sigmoid(Z2)\n",
        "    \n",
        "    # backpropagation\n",
        "    E1 = A2 - y_train\n",
        "    dW1 = E1 * A2 * (1 - A2)\n",
        "\n",
        "    E2 = np.dot(dW1, W2.T)\n",
        "    dW2 = E2 * A1 * (1 - A1)\n",
        "\n",
        "    \n",
        "    # weight updates\n",
        "    W2_update = np.dot(A1.T, dW1) / N\n",
        "    W1_update = np.dot(X_train.T, dW2) / N\n",
        "\n",
        "    W2 = W2 - learning_rate * W2_update\n",
        "    W1 = W1 - learning_rate * W1_update"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25de6bc9",
      "metadata": {
        "id": "25de6bc9"
      },
      "source": [
        "## Step 3.) Testing our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4adce684",
      "metadata": {
        "id": "4adce684",
        "outputId": "158f7c46-b25c-4bd2-da0d-f5f3adf78f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Meaned Squared Error : 0.03943592983850345\n",
            "Accuracy : 1.0\n"
          ]
        }
      ],
      "source": [
        "# feedforward propagation\n",
        "# on hidden layer\n",
        "Z1 = np.dot(X_train, W1)\n",
        "A1 = sigmoid(Z1)\n",
        "\n",
        "# on output layer\n",
        "Z2 = np.dot(A1, W2)\n",
        "A2 = sigmoid(Z2)\n",
        "    \n",
        "# Calculating error\n",
        "print('Meaned Squared Error :',mean_squared_error(A2, y_train))\n",
        "print('Accuracy :',accuracy(A2, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e794e765",
      "metadata": {
        "id": "e794e765"
      },
      "source": [
        "## Conclusion\n",
        "#### Since we are able to achieve Actual Output in the Predicted Output of our Testing data , our model seems be correct and working"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2f155fbeb9494e5ce992090b8427abe3542dae7719d8ea0d05cb0b78608edd18"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}